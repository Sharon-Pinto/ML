import pandas as pd
import numpy as np
from mlxtend.plotting import plot_decision_regions #To plot decision boundaries

df = pd.DataFrame()

df['X1'] = [1,2,3,4,5,6,6,7,9,9]
df['X2'] = [5,3,6,8,1,9,5,8,9,2]
df['label'] = [1,1,0,1,0,1,0,1,0,0]

df 

import seaborn as sns
sns.scatterplot(x=df['X1'],y=df['X2'],hue=df['label'])

df['weights'] = 1/df.shape[0]
df

from sklearn.tree import DecisionTreeClassifier

dt1 = DecisionTreeClassifier(max_depth=1) # create decision tree classifieer with decsion stump (max dept=1)

# extract X and y
X = df.iloc[:,0:2].values
y = df.iloc[:,2].values

dt1.fit(X,y)

from sklearn.tree import plot_tree
plot_tree(dt1)

plot_decision_regions(X, y, clf=dt1, legend=2)

df['y_pred'] = dt1.predict(X)
df

# function to compute the model weight
def calculate_model_weight(error):
  return 0.5*np.log((1-error)/(error))
#Calculate the weight of the first model based on its error rate
alpha1 = calculate_model_weight(0.3)  # 3 misclassification weigts (in this case 3 misclassification)
alpha1

def update_row_weights(row,alpha=0.423):
  if row['label'] == row['y_pred']:
    return row['weights'] * np.exp(-alpha)
  else:
    return row['weights'] * np.exp(alpha)

df['updated_weights'] = df.apply(update_row_weights,axis=1)
df

# the sum of the update may be less then 1
df['updated_weights'].sum()
 
df['nomalized_weights'] = df['updated_weights']/df['updated_weights'].sum()
df

df['nomalized_weights'].sum()
 
# Now we will create the range
df['cumsum_upper'] = np.cumsum(df['nomalized_weights'])
df['cumsum_lower'] = df['cumsum_upper'] - df['nomalized_weights']
# see the range
df[['X1','X2','label','weights','y_pred','updated_weights','cumsum_lower','cumsum_upper']]

# we will use random number generator
def create_new_dataset(df):
  indices = []
  for i in range(df.shape[0]):
    a = np.random.random()
    for index,row in df.iterrows():
      if row['cumsum_upper'] > a and a > row['cumsum_lower']: # check the range and get the index
        indices.append(index)
  return indices

index_values = create_new_dataset(df)
index_values

# create new dataframe from old dataframe with the rows selected above and the respective colums.
second_df = df.iloc[index_values,[0,1,2,3]]
second_df
 

# make second decsion tree
dt2 = DecisionTreeClassifier(max_depth=1)
# get the features and outputs
X = second_df.iloc[:,0:2].values
y = second_df.iloc[:,2].values
# train the decsion tree on the new data
dt2.fit(X,y)

plot_tree(dt2)
plot_decision_regions(X, y, clf=dt2, legend=2)

second_df['y_pred'] = dt2.predict(X)
second_df

alpha2 = calculate_model_weight(0.1)
# note when there is no misclassification then error may be zero. then it will be problem. then you can add a very small number to overcome this proble. in scikit it is solved.

alpha2
# Step 4 - Update weights
def update_row_weights(row,alpha=1.09):
  if row['label'] == row['y_pred']:
    return row['weights'] * np.exp(-alpha)
  else:
    return row['weights'] * np.exp(alpha)

second_df['updated_weights'] = second_df.apply(update_row_weights,axis=1)
second_df

# normalise the weights
second_df['nomalized_weights'] = second_df['updated_weights']/second_df['updated_weights'].sum()
second_df

second_df['nomalized_weights'].sum()
second_df['cumsum_upper'] = np.cumsum(second_df['nomalized_weights'])
second_df['cumsum_lower'] = second_df['cumsum_upper'] - second_df['nomalized_weights']
second_df[['X1','X2','label','weights','y_pred','nomalized_weights','cumsum_lower','cumsum_upper']]


